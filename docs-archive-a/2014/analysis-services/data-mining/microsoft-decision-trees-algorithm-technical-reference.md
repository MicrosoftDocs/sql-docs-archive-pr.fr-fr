---
title: Informations techniques de référence sur l’algorithme MDT (Microsoft Decision Trees) | Microsoft Docs
ms.custom: ''
ms.date: 06/13/2017
ms.prod: sql-server-2014
ms.reviewer: ''
ms.technology: analysis-services
ms.topic: conceptual
helpviewer_keywords:
- MAXIMUM_INPUT_ATTRIBUTES parameter
- SPLIT_METHOD parameter
- MINIMUM_SUPPORT parameter
- MAXIMUM_OUTPUT_ATTRIBUTES parameter
- FORCED_REGRESSOR parameter
- decision tree algorithms [Analysis Services]
- decision trees [Analysis Services]
- COMPLEXITY_PENALTY parameter
- SCORE_METHOD parameter
ms.assetid: 1e9f7969-0aa6-465a-b3ea-57b8d1c7a1fd
author: minewiskan
ms.author: owend
ms.openlocfilehash: 0cd0cd3100d0ed1213183815ae41f17cee3baa68
ms.sourcegitcommit: ad4d92dce894592a259721a1571b1d8736abacdb
ms.translationtype: MT
ms.contentlocale: fr-FR
ms.lasthandoff: 08/04/2020
ms.locfileid: "87611398"
---
# <a name="microsoft-decision-trees-algorithm-technical-reference"></a><span data-ttu-id="0f316-102">Références techniques relatives à l'algorithme MDT (Microsoft Decision Trees)</span><span class="sxs-lookup"><span data-stu-id="0f316-102">Microsoft Decision Trees Algorithm Technical Reference</span></span>
  <span data-ttu-id="0f316-103">L'algorithme MDT ( [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees) est un algorithme hybride qui incorpore des méthodes différentes pour créer une arborescence et prend en charge plusieurs tâches analytiques, dont la régression, la classification et l'association.</span><span class="sxs-lookup"><span data-stu-id="0f316-103">The [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees algorithm is a hybrid algorithm that incorporates different methods for creating a tree, and supports multiple analytic tasks, including regression, classification, and association.</span></span> <span data-ttu-id="0f316-104">L'algorithme MDT (Microsoft Decision Trees) prend en charge la modélisation des attributs discrets et continus.</span><span class="sxs-lookup"><span data-stu-id="0f316-104">The Microsoft Decision Trees algorithm supports modeling of both discrete and continuous attributes.</span></span>  
  
 <span data-ttu-id="0f316-105">Cette rubrique explique l'implémentation de l'algorithme, décrit la façon de personnaliser le comportement de l'algorithme pour différentes tâches et fournit des liens vers des informations supplémentaires sur l'interrogation des modèles d'arbre de décision.</span><span class="sxs-lookup"><span data-stu-id="0f316-105">This topic explains the implementation of the algorithm, describes how to customize the behavior of the algorithm for different tasks, and provides links to additional information about querying decision tree models.</span></span>  
  
## <a name="implementation-of-the-decision-trees-algorithm"></a><span data-ttu-id="0f316-106">Implémentation de l'algorithme MDT (Microsoft Decision Trees)</span><span class="sxs-lookup"><span data-stu-id="0f316-106">Implementation of the Decision Trees Algorithm</span></span>  
 <span data-ttu-id="0f316-107">L'algorithme MDT (Microsoft Decision Trees) applique l'approche bayésienne pour acquérir les modèles causaux d'interaction en obtenant des distributions ultérieures approximatives pour les modèles.</span><span class="sxs-lookup"><span data-stu-id="0f316-107">The Microsoft Decision Trees algorithm applies the Bayesian approach to learning causal interaction models by obtaining approximate posterior distributions for the models.</span></span> <span data-ttu-id="0f316-108">Pour une explication détaillée de cette approche, consultez l'article sur le site Microsoft Research, par [Structure et apprentissage de paramètres](https://go.microsoft.com/fwlink/?LinkId=237640&clcid=0x409).</span><span class="sxs-lookup"><span data-stu-id="0f316-108">For a detailed explanation of this approach, see the paper on the Microsoft Research site, by [Structure and Parameter Learning](https://go.microsoft.com/fwlink/?LinkId=237640&clcid=0x409).</span></span>  
  
 <span data-ttu-id="0f316-109">La méthodologie d'évaluation de la valeur d'information des *à priori* nécessaires pour l'apprentissage repose sur l' *équivalence de probabilité*.</span><span class="sxs-lookup"><span data-stu-id="0f316-109">The methodology for assessing the information value of the *priors* needed for learning is based on the assumption of *likelihood equivalence*.</span></span> <span data-ttu-id="0f316-110">Cette hypothèse indique que les données ne doivent pas aider à discriminer des structures de réseau qui représentent autrement les mêmes assertions d'indépendance conditionnelle.</span><span class="sxs-lookup"><span data-stu-id="0f316-110">This assumption says that data should not help to discriminate network structures that otherwise represent the same assertions of conditional independence.</span></span> <span data-ttu-id="0f316-111">Il est supposé que chaque cas a un réseau antérieur bayésien unique et une mesure unique de confiance pour ce réseau.</span><span class="sxs-lookup"><span data-stu-id="0f316-111">Each case is assumed to have a single Bayesian prior network and a single measure of confidence for that network.</span></span>  
  
 <span data-ttu-id="0f316-112">Utilisant ces réseaux antérieurs, l'algorithme calcule ensuite les *probabilités postérieures* relatives de structures de réseau selon les données d'apprentissage actuelles et identifie les structures de réseau qui ont les probabilités postérieures les plus élevées.</span><span class="sxs-lookup"><span data-stu-id="0f316-112">Using these prior networks, the algorithm then computes the relative *posterior probabilities* of network structures given the current training data, and identifies the network structures that have the highest posterior probabilities.</span></span>  
  
 <span data-ttu-id="0f316-113">L'algorithme MDT (Microsoft Decision Trees) utilise des méthodes différentes pour calculer la meilleure arborescence.</span><span class="sxs-lookup"><span data-stu-id="0f316-113">The Microsoft Decision Trees algorithm uses different methods to compute the best tree.</span></span> <span data-ttu-id="0f316-114">La méthode utilisée dépend de la tâche, qui peut être une régression linéaire, une classification ou une analyse d'association.</span><span class="sxs-lookup"><span data-stu-id="0f316-114">The method used depends on the task, which can be linear regression, classification, or association analysis.</span></span> <span data-ttu-id="0f316-115">Un modèle unique peut contenir plusieurs arborescences pour des attributs prédictibles différents.</span><span class="sxs-lookup"><span data-stu-id="0f316-115">A single model can contain multiple trees for different predictable attributes.</span></span> <span data-ttu-id="0f316-116">De plus, chaque arborescence peut contenir plusieurs branches, selon le nombre d'attributs et de valeurs existant dans les données.</span><span class="sxs-lookup"><span data-stu-id="0f316-116">Moreover, each tree can contain multiple branches, depending on how many attributes and values there are in the data.</span></span> <span data-ttu-id="0f316-117">La forme et la profondeur de l'arborescence générée dans un modèle particulier dépendent de la méthode de résultat et d'autres paramètres utilisés.</span><span class="sxs-lookup"><span data-stu-id="0f316-117">The shape and depth of the tree built in a particular model depends on the scoring method and other parameters that were used.</span></span> <span data-ttu-id="0f316-118">Les modifications des paramètres peuvent également affecter le lieu de fractionnement des nœuds.</span><span class="sxs-lookup"><span data-stu-id="0f316-118">Changes in the parameters can also affect where the nodes split.</span></span>  
  
### <a name="building-the-tree"></a><span data-ttu-id="0f316-119">Génération de l'arborescence</span><span class="sxs-lookup"><span data-stu-id="0f316-119">Building the Tree</span></span>  
 <span data-ttu-id="0f316-120">Lorsque l'algorithme MDT (Microsoft Decision Trees) crée le jeu de valeurs d'entrée possibles, il effectue *feature selection* pour identifier les attributs et valeurs qui fournissent le plus d'informations et ne prend pas en considération les valeurs qui sont très rares.</span><span class="sxs-lookup"><span data-stu-id="0f316-120">When the Microsoft Decision Trees algorithm creates the set of possible input values, it performs *feature selection* to identify the attributes and values that provide the most information, and removes from consideration the values that are very rare.</span></span> <span data-ttu-id="0f316-121">L'algorithme regroupe également des valeurs dans des *bacs*pour créer des regroupements de valeurs qui peuvent être traitées comme une unité afin d'optimiser les performances.</span><span class="sxs-lookup"><span data-stu-id="0f316-121">The algorithm also groups values into *bins*, to create groupings of values that can be processed as a unit to optimize performance.</span></span>  
  
 <span data-ttu-id="0f316-122">Une arborescence est générée en déterminant les corrélations entre une entrée et le résultat ciblé.</span><span class="sxs-lookup"><span data-stu-id="0f316-122">A tree is built by determining the correlations between an input and the targeted outcome.</span></span> <span data-ttu-id="0f316-123">Une fois que tous les attributs ont été corrélés, l'algorithme identifie l'attribut unique qui sépare le mieux les résultats.</span><span class="sxs-lookup"><span data-stu-id="0f316-123">After all the attributes have been correlated, the algorithm identifies the single attribute that most cleanly separates the outcomes.</span></span> <span data-ttu-id="0f316-124">Ce point de meilleure séparation est mesuré en utilisant une équation qui calcule le gain d'informations.</span><span class="sxs-lookup"><span data-stu-id="0f316-124">This point of the best separation is measured by using an equation that calculates information gain.</span></span> <span data-ttu-id="0f316-125">L'attribut qui a le meilleur score en termes de gain d'informations est utilisé pour diviser les cas en sous-ensembles, qui subissent ensuite une analyse récursive par le même processus jusqu'à ce que l'arborescence ne puisse plus être fractionnée.</span><span class="sxs-lookup"><span data-stu-id="0f316-125">The attribute that has the best score for information gain is used to divide the cases into subsets, which are then recursively analyzed by the same process, until the tree cannot be split any more.</span></span>  
  
 <span data-ttu-id="0f316-126">L'équation exacte utilisée pour évaluer le gain d'informations dépend des paramètres définis lorsque vous avez créé l'algorithme, du type de données de la colonne prédictible et du type de données de l'entrée.</span><span class="sxs-lookup"><span data-stu-id="0f316-126">The exact equation used to evaluate information gain depends on the parameters set when you created the algorithm, the data type of the predictable column, and the data type of the input.</span></span>  
  
### <a name="discrete-and-continuous-inputs"></a><span data-ttu-id="0f316-127">Entrées discrètes et continues</span><span class="sxs-lookup"><span data-stu-id="0f316-127">Discrete and Continuous Inputs</span></span>  
 <span data-ttu-id="0f316-128">Lorsque l'attribut prédictible est discret et les entrées sont discrètes, le comptage des résultats par entrée consiste à créer une matrice et à générer des scores pour chaque cellule de la matrice.</span><span class="sxs-lookup"><span data-stu-id="0f316-128">When the predictable attribute is discrete and the inputs are discrete, counting the outcomes per input is a matter of creating a matrix and generating scores for each cell in the matrix.</span></span>  
  
 <span data-ttu-id="0f316-129">Toutefois, lorsque l'attribut prédictible est discret et les entrées sont continues, l'entrée des colonnes continues est automatiquement discrétisée.</span><span class="sxs-lookup"><span data-stu-id="0f316-129">However, when the predictable attribute is discrete and the inputs are continuous, the input of the continuous columns are automatically discretized.</span></span> <span data-ttu-id="0f316-130">Vous pouvez accepter la valeur par défaut et faire en sorte que [!INCLUDE[ssASnoversion](../../includes/ssasnoversion-md.md)] recherche le nombre optimal de bacs, ou vous pouvez contrôler la façon de discrétiser les entrées continues en définissant les propriétés <xref:Microsoft.AnalysisServices.ScalarMiningStructureColumn.DiscretizationMethod%2A> et <xref:Microsoft.AnalysisServices.ScalarMiningStructureColumn.DiscretizationBucketCount%2A> .</span><span class="sxs-lookup"><span data-stu-id="0f316-130">You can accept the default and have [!INCLUDE[ssASnoversion](../../includes/ssasnoversion-md.md)] find the optimum number of bins, or you can control the manner in which continuous inputs are discretized by setting the <xref:Microsoft.AnalysisServices.ScalarMiningStructureColumn.DiscretizationMethod%2A> and <xref:Microsoft.AnalysisServices.ScalarMiningStructureColumn.DiscretizationBucketCount%2A> properties.</span></span> <span data-ttu-id="0f316-131">Pour plus d’informations, consultez [Modifier la discrétisation d’une colonne dans un modèle d’exploration de données](change-the-discretization-of-a-column-in-a-mining-model.md).</span><span class="sxs-lookup"><span data-stu-id="0f316-131">For more information, see [Change the Discretization of a Column in a Mining Model](change-the-discretization-of-a-column-in-a-mining-model.md).</span></span>  
  
 <span data-ttu-id="0f316-132">Pour les attributs continus, l'algorithme utilise la régression linéaire pour déterminer où un arbre de décision se divise.</span><span class="sxs-lookup"><span data-stu-id="0f316-132">For continuous attributes, the algorithm uses linear regression to determine where a decision tree splits.</span></span>  
  
 <span data-ttu-id="0f316-133">Lorsque l'attribut prédictible est un type de données numériques continues, la sélection des fonctionnalités est également appliquée aux sorties pour réduire le nombre possible de résultats et générer le modèle plus vite.</span><span class="sxs-lookup"><span data-stu-id="0f316-133">When the predictable attribute is a continuous numeric data type, feature selection is applied to the outputs as well, to reduce the possible number of outcomes and build the model faster.</span></span> <span data-ttu-id="0f316-134">Vous pouvez modifier le seuil pour la sélection des fonctionnalités et augmenter ou réduire ainsi le nombre de valeurs possibles en définissant le paramètre MAXIMUM_OUTPUT_ATTRIBUTES.</span><span class="sxs-lookup"><span data-stu-id="0f316-134">You can change the threshold for feature selection and thereby increase or decrease the number of possible values by setting the MAXIMUM_OUTPUT_ATTRIBUTES parameter.</span></span>  
  
 <span data-ttu-id="0f316-135">Pour une explication plus détaillée de la façon dont l'algorithme MDT ( [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees) utilise des colonnes prédictibles discrètes, consultez [Réseaux bayésiens : connaissance et données statistiques](https://go.microsoft.com/fwlink/?LinkId=45963).</span><span class="sxs-lookup"><span data-stu-id="0f316-135">For a more detained explanation about how the [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees algorithm works with discrete predictable columns, see [Learning Bayesian Networks: The Combination of Knowledge and Statistical Data](https://go.microsoft.com/fwlink/?LinkId=45963).</span></span> <span data-ttu-id="0f316-136">Pour plus d’informations sur le fonctionnement de l’algorithme MDT ( [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees) avec une colonne prédictible continue, consultez l’annexe disponible dans le document [Autoregressive Tree Models for Time-Series Analysis](https://go.microsoft.com/fwlink/?LinkId=45966).</span><span class="sxs-lookup"><span data-stu-id="0f316-136">For more information about how the [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees algorithm works with a continuous predictable column, see the appendix of [Autoregressive Tree Models for Time-Series Analysis](https://go.microsoft.com/fwlink/?LinkId=45966).</span></span>  
  
### <a name="scoring-methods-and-feature-selection"></a><span data-ttu-id="0f316-137">Résultat des méthodes et sélection des fonctionnalités</span><span class="sxs-lookup"><span data-stu-id="0f316-137">Scoring Methods and Feature Selection</span></span>  
 <span data-ttu-id="0f316-138">L'algorithme MDT (Microsoft Decision Trees) offre trois formules pour définir le score du gain d'informations : l'entropie de Shannon, le réseau bayésien avec a priori K2 et le réseau bayésien de Dirichlet avec a priori uniforme.</span><span class="sxs-lookup"><span data-stu-id="0f316-138">The Microsoft Decision Trees algorithm offers three formulas for scoring information gain: Shannon's entropy, Bayesian network with K2 prior, and Bayesian network with a uniform Dirichlet distribution of priors.</span></span> <span data-ttu-id="0f316-139">Les trois méthodes sont bien établies dans le champ d'exploration de données.</span><span class="sxs-lookup"><span data-stu-id="0f316-139">All three methods are well established in the data mining field.</span></span> <span data-ttu-id="0f316-140">Nous vous recommandons d'expérimenter des paramètres et des méthodes différents pour déterminer ceux qui fournissent les meilleurs résultats.</span><span class="sxs-lookup"><span data-stu-id="0f316-140">We recommend that you experiment with different parameters and scoring methods to determine which provides the best results.</span></span> <span data-ttu-id="0f316-141">Pour plus d'informations sur ces méthodes de calcul de score, consultez [Feature Selection](../../sql-server/install/feature-selection.md).</span><span class="sxs-lookup"><span data-stu-id="0f316-141">For more information about these scoring methods, see [Feature Selection](../../sql-server/install/feature-selection.md).</span></span>  
  
 <span data-ttu-id="0f316-142">Tous les algorithmes d'exploration de données [!INCLUDE[ssASnoversion](../../includes/ssasnoversion-md.md)] utilisent automatiquement la sélection des fonctionnalités pour améliorer l'analyse et réduire la charge de traitement.</span><span class="sxs-lookup"><span data-stu-id="0f316-142">All [!INCLUDE[ssASnoversion](../../includes/ssasnoversion-md.md)] data mining algorithms automatically use feature selection to improve analysis and reduce processing load.</span></span> <span data-ttu-id="0f316-143">La méthode utilisée pour la sélection des fonctionnalités dépend de l'algorithme utilisé pour générer le modèle.</span><span class="sxs-lookup"><span data-stu-id="0f316-143">The method used for feature selection depends on the algorithm that is used to build the model.</span></span> <span data-ttu-id="0f316-144">Les paramètres d'algorithme qui contrôlent la sélection des fonctionnalités pour un modèle d'arbre de décision sont MAXIMUM_INPUT_ATTRIBUTES et MAXIMUM_OUTPUT.</span><span class="sxs-lookup"><span data-stu-id="0f316-144">The algorithm parameters that control feature selection for a decision trees model are MAXIMUM_INPUT_ATTRIBUTES and MAXIMUM_OUTPUT.</span></span>  
  
|<span data-ttu-id="0f316-145">Algorithm</span><span class="sxs-lookup"><span data-stu-id="0f316-145">Algorithm</span></span>|<span data-ttu-id="0f316-146">Méthode d'analyse</span><span class="sxs-lookup"><span data-stu-id="0f316-146">Method of analysis</span></span>|<span data-ttu-id="0f316-147">Commentaires</span><span class="sxs-lookup"><span data-stu-id="0f316-147">Comments</span></span>|  
|---------------|------------------------|--------------|  
|<span data-ttu-id="0f316-148">Arbres de décision</span><span class="sxs-lookup"><span data-stu-id="0f316-148">Decision Trees</span></span>|<span data-ttu-id="0f316-149">Score d'intérêt et de pertinence</span><span class="sxs-lookup"><span data-stu-id="0f316-149">Interestingness score</span></span><br /><br /> <span data-ttu-id="0f316-150">Entropie de Shannon</span><span class="sxs-lookup"><span data-stu-id="0f316-150">Shannon's Entropy</span></span><br /><br /> <span data-ttu-id="0f316-151">Bayésien avec a priori K2</span><span class="sxs-lookup"><span data-stu-id="0f316-151">Bayesian with K2 Prior</span></span><br /><br /> <span data-ttu-id="0f316-152">Équivalent bayésien de Dirichlet avec a priori uniforme (par défaut)</span><span class="sxs-lookup"><span data-stu-id="0f316-152">Bayesian Dirichlet with uniform prior (default)</span></span>|<span data-ttu-id="0f316-153">Si des colonnes contiennent des valeurs continues non binaires, le score d'intérêt et de pertinence est utilisé pour toutes les colonnes afin de garantir la cohérence.</span><span class="sxs-lookup"><span data-stu-id="0f316-153">If any columns contain non-binary continuous values, the interestingness score is used for all columns, to ensure consistency.</span></span> <span data-ttu-id="0f316-154">Sinon, la méthode par défaut ou spécifiée est utilisée.</span><span class="sxs-lookup"><span data-stu-id="0f316-154">Otherwise, the default or specified method is used.</span></span>|  
|<span data-ttu-id="0f316-155">Régression linéaire</span><span class="sxs-lookup"><span data-stu-id="0f316-155">Linear Regression</span></span>|<span data-ttu-id="0f316-156">Score d'intérêt et de pertinence</span><span class="sxs-lookup"><span data-stu-id="0f316-156">Interestingness score</span></span>|<span data-ttu-id="0f316-157">La régression linéaire utilise uniquement l'intérêt et la pertinence car elle ne prend en charge que les colonnes continues.</span><span class="sxs-lookup"><span data-stu-id="0f316-157">Linear Regression only uses interestingness, because it only supports continuous columns.</span></span>|  
  
### <a name="scalability-and-performance"></a><span data-ttu-id="0f316-158">Extensibilité et performance</span><span class="sxs-lookup"><span data-stu-id="0f316-158">Scalability and Performance</span></span>  
 <span data-ttu-id="0f316-159">La classification est une stratégie d'exploration de données importante.</span><span class="sxs-lookup"><span data-stu-id="0f316-159">Classification is an important data mining strategy.</span></span> <span data-ttu-id="0f316-160">En général, la quantité d'informations nécessaire pour classifier les cas grandit de façon directement proportionnelle au nombre d'enregistrements d'entrée.</span><span class="sxs-lookup"><span data-stu-id="0f316-160">Generally, the amount of information that is needed to classify the cases grows in direct proportion to the number of input records.</span></span> <span data-ttu-id="0f316-161">Cela limite la taille des données qui peuvent être classées.</span><span class="sxs-lookup"><span data-stu-id="0f316-161">This limits the size of the data that can be classified.</span></span> <span data-ttu-id="0f316-162">L'algorithme MDT (Microsoft Decision Trees) utilise les méthodes suivantes pour résoudre ces problèmes, améliorer les performances et éliminer les restrictions de mémoire :</span><span class="sxs-lookup"><span data-stu-id="0f316-162">The Microsoft Decision Trees algorithm using uses the following methods to resolve these problems, improve performance, and eliminate memory restrictions:</span></span>  
  
-   <span data-ttu-id="0f316-163">Sélection des fonctionnalités pour optimiser la sélection des attributs.</span><span class="sxs-lookup"><span data-stu-id="0f316-163">Feature selection to optimize the selection of attributes.</span></span>  
  
-   <span data-ttu-id="0f316-164">Score bayésien pour contrôler la croissance de l'arbre.</span><span class="sxs-lookup"><span data-stu-id="0f316-164">Bayesian scoring to control tree growth.</span></span>  
  
-   <span data-ttu-id="0f316-165">Optimisation de mise en bac pour les attributs continus.</span><span class="sxs-lookup"><span data-stu-id="0f316-165">Optimization of binning for continuous attributes.</span></span>  
  
-   <span data-ttu-id="0f316-166">Regroupement dynamique de valeurs d'entrée pour déterminer les valeurs les plus importantes.</span><span class="sxs-lookup"><span data-stu-id="0f316-166">Dynamic grouping of input values to determine the most important values.</span></span>  
  
 <span data-ttu-id="0f316-167">L'algorithme MDT (Microsoft Decision Trees) est rapide et évolutif. Il a été conçu pour être facilement mis en parallèle, ce qui signifie que tous les processeurs fonctionnent ensemble pour générer un seul modèle cohérent.</span><span class="sxs-lookup"><span data-stu-id="0f316-167">The Microsoft Decision Trees algorithm is fast and scalable, and has been designed to be easily parallelized, meaning that all processors work together to build a single, consistent model.</span></span> <span data-ttu-id="0f316-168">La combinaison de ces caractéristiques fait du classifieur d'arbre de décision un outil idéal pour l'exploration de données.</span><span class="sxs-lookup"><span data-stu-id="0f316-168">The combination of these characteristics makes the decision-tree classifier an ideal tool for data mining.</span></span>  
  
 <span data-ttu-id="0f316-169">Si les contraintes de performances sont importantes, vous pouvez améliorer le temps de traitement pendant l'apprentissage d'un modèle d'arbre de décision en utilisant les méthodes suivantes.</span><span class="sxs-lookup"><span data-stu-id="0f316-169">If performance constraints are severe, you might be able to improve processing time during the training of a decision tree model by using the following methods.</span></span> <span data-ttu-id="0f316-170">Toutefois, dans cette éventualité, sachez que la suppression d'attributs en vue d'améliorer les performances de traitement modifiera les résultats du modèle et le rendra peut-être moins représentatif de la totalité de la population.</span><span class="sxs-lookup"><span data-stu-id="0f316-170">However, if you do so, be aware that eliminating attributes to improve processing performance will change the results of the model, and possibly make it less representative of the total population.</span></span>  
  
-   <span data-ttu-id="0f316-171">Augmentez la valeur du paramètre COMPLEXITY_PENALTY pour limiter la croissance de l'arbre.</span><span class="sxs-lookup"><span data-stu-id="0f316-171">Increase the value of the COMPLEXITY_PENALTY parameter to limit tree growth.</span></span>  
  
-   <span data-ttu-id="0f316-172">Limitez le numéro d'éléments dans les modèles d'association pour limiter le nombre d'arborescences générées.</span><span class="sxs-lookup"><span data-stu-id="0f316-172">Limit the number of items in association models to limit the number of trees that are built.</span></span>  
  
-   <span data-ttu-id="0f316-173">Augmentez la valeur du paramètre MINIMUM_SUPPORT pour éviter le surajustement.</span><span class="sxs-lookup"><span data-stu-id="0f316-173">Increase the value of the MINIMUM_SUPPORT parameter to avoid overfitting.</span></span>  
  
-   <span data-ttu-id="0f316-174">Restreignez le nombre de valeurs discrètes pour tout attribut à 10 ou moins.</span><span class="sxs-lookup"><span data-stu-id="0f316-174">Restrict the number of discrete values for any attribute to 10 or less.</span></span> <span data-ttu-id="0f316-175">Vous pouvez essayer de regrouper les valeurs de différentes façons dans les différents modèles.</span><span class="sxs-lookup"><span data-stu-id="0f316-175">You might try grouping values in different ways in different models.</span></span>  
  
    > [!NOTE]  
    >  <span data-ttu-id="0f316-176">Vous pouvez utiliser les outils d'exploration de données disponibles dans  [!INCLUDE[ssISCurrent](../../includes/ssiscurrent-md.md)] pour visualiser la distribution de valeurs dans vos données et regrouper convenablement vos valeurs avant de commencer l'exploration de données.</span><span class="sxs-lookup"><span data-stu-id="0f316-176">You can use the data exploration tools available in  [!INCLUDE[ssISCurrent](../../includes/ssiscurrent-md.md)] to visualize the distribution of values in your data and group your values appropriately before beginning data mining.</span></span> <span data-ttu-id="0f316-177">Pour plus d’informations, consultez [Tâche de profilage des données et visionneuse](../../integration-services/control-flow/data-profiling-task-and-viewer.md).</span><span class="sxs-lookup"><span data-stu-id="0f316-177">For more information, see [Data Profiling Task and Viewer](../../integration-services/control-flow/data-profiling-task-and-viewer.md).</span></span> <span data-ttu-id="0f316-178">Vous pouvez également utiliser les [compléments d’exploration de données pour Excel 2007](https://www.microsoft.com/download/details.aspx?id=8569)pour explorer, regrouper et réétiqueter les données dans Microsoft Excel.</span><span class="sxs-lookup"><span data-stu-id="0f316-178">You can also use the [Data Mining Add-ins for Excel 2007](https://www.microsoft.com/download/details.aspx?id=8569), to explore, group and relabel data in Microsoft Excel.</span></span>  
  
## <a name="customizing-the-decision-trees-algorithm"></a><span data-ttu-id="0f316-179">Personnalisation de l'algorithme MDT (Microsoft Decision Trees).</span><span class="sxs-lookup"><span data-stu-id="0f316-179">Customizing the Decision Trees Algorithm</span></span>  
 <span data-ttu-id="0f316-180">L'algorithme MDT ( [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees) prend en charge des paramètres qui affectent les performances et la précision du modèle d'exploration de données résultant.</span><span class="sxs-lookup"><span data-stu-id="0f316-180">The [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees algorithm supports parameters that affect the performance and accuracy of the resulting mining model.</span></span> <span data-ttu-id="0f316-181">Vous pouvez également définir des indicateurs de modélisation sur les colonnes du modèle ou de la structure d'exploration de données pour contrôler le mode de traitement des données.</span><span class="sxs-lookup"><span data-stu-id="0f316-181">You can also set modeling flags on the mining model columns or mining structure columns to control the way that data is processed.</span></span>  
  
> [!NOTE]  
>  <span data-ttu-id="0f316-182">L'algorithme MDT est disponible dans toutes les éditions de [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)]; toutefois, certains paramètres avancés permettant de personnaliser le comportement de l'algorithme MDT sont disponibles uniquement dans les éditions spécifiques de [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)].</span><span class="sxs-lookup"><span data-stu-id="0f316-182">The Microsoft Decision Trees algorithm is available in all editions of [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)]; however, some advanced parameters for customizing the behavior of the Microsoft Decision Trees algorithm are available for use only in specific editions of [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)].</span></span> <span data-ttu-id="0f316-183">Pour obtenir la liste des fonctionnalités prises en charge par les éditions de [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)] , consultez [fonctionnalités prises en charge par les éditions de SQL Server 2012](https://go.microsoft.com/fwlink/?linkid=232473) ( https://go.microsoft.com/fwlink/?linkid=232473) .</span><span class="sxs-lookup"><span data-stu-id="0f316-183">For a list of features that are supported by the editions of [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)], see [Features Supported by the Editions of SQL Server 2012](https://go.microsoft.com/fwlink/?linkid=232473) (https://go.microsoft.com/fwlink/?linkid=232473).</span></span>  
  
### <a name="setting-algorithm-parameters"></a><span data-ttu-id="0f316-184">Définition des paramètres de l'algorithme</span><span class="sxs-lookup"><span data-stu-id="0f316-184">Setting Algorithm Parameters</span></span>  
 <span data-ttu-id="0f316-185">Le tableau suivant décrit les paramètres que vous pouvez utiliser avec l'algorithme MDT ( [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees).</span><span class="sxs-lookup"><span data-stu-id="0f316-185">The following table describes the parameters that you can use with the [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees algorithm.</span></span>  
  
 <span data-ttu-id="0f316-186">*COMPLEXITY_PENALTY*</span><span class="sxs-lookup"><span data-stu-id="0f316-186">*COMPLEXITY_PENALTY*</span></span>  
 <span data-ttu-id="0f316-187">Contrôle la croissance de l'arbre de décision.</span><span class="sxs-lookup"><span data-stu-id="0f316-187">Controls the growth of the decision tree.</span></span> <span data-ttu-id="0f316-188">Une valeur faible entraîne l'augmentation du nombre de fractionnements, alors qu'une valeur élevée entraîne la diminution du nombre de fractionnements.</span><span class="sxs-lookup"><span data-stu-id="0f316-188">A low value increases the number of splits, and a high value decreases the number of splits.</span></span> <span data-ttu-id="0f316-189">La valeur par défaut dépend du nombre d'attributs pour un modèle particulier, comme cela est décrit dans la liste suivante :</span><span class="sxs-lookup"><span data-stu-id="0f316-189">The default value is based on the number of attributes for a particular model, as described in the following list:</span></span>  
  
-   <span data-ttu-id="0f316-190">De 1 à 9 attributs, la valeur par défaut est égale à 0,5.</span><span class="sxs-lookup"><span data-stu-id="0f316-190">For 1 through 9 attributes, the default is 0.5.</span></span>  
  
-   <span data-ttu-id="0f316-191">De 10 à 99 attributs, la valeur par défaut est égale à 0,9.</span><span class="sxs-lookup"><span data-stu-id="0f316-191">For 10 through 99 attributes, the default is 0.9.</span></span>  
  
-   <span data-ttu-id="0f316-192">À partir de 100 attributs, la valeur par défaut est égale à 0,99.</span><span class="sxs-lookup"><span data-stu-id="0f316-192">For 100 or more attributes, the default is 0.99.</span></span>  
  
 <span data-ttu-id="0f316-193">*FORCE_REGRESSOR*</span><span class="sxs-lookup"><span data-stu-id="0f316-193">*FORCE_REGRESSOR*</span></span>  
 <span data-ttu-id="0f316-194">Force l'algorithme à utiliser les colonnes spécifiées en tant que régresseurs, quelle que soit leur importance selon les calculs de l'algorithme.</span><span class="sxs-lookup"><span data-stu-id="0f316-194">Forces the algorithm to use the specified columns as regressors, regardless of the importance of the columns as calculated by the algorithm.</span></span> <span data-ttu-id="0f316-195">Ce paramètre est utilisé uniquement pour les arbres de décision qui prévoient un attribut continu.</span><span class="sxs-lookup"><span data-stu-id="0f316-195">This parameter is only used for decision trees that are predicting a continuous attribute.</span></span>  
  
> [!NOTE]  
>  <span data-ttu-id="0f316-196">En définissant ce paramètre, vous forcez l'algorithme à essayer d'utiliser l'attribut comme un régresseur.</span><span class="sxs-lookup"><span data-stu-id="0f316-196">By setting this parameter, you force the algorithm to try to use the attribute as a regressor.</span></span> <span data-ttu-id="0f316-197">Toutefois, l'utilisation réelle de l'attribut en tant que régresseur dans le modèle final dépend des résultats d'analyse.</span><span class="sxs-lookup"><span data-stu-id="0f316-197">However, whether the attribute is actually used as a regressor in the final model depends on the results of analysis.</span></span> <span data-ttu-id="0f316-198">Vous pouvez savoir quelles colonnes ont été utilisées comme régresseurs en interrogeant le contenu du modèle.</span><span class="sxs-lookup"><span data-stu-id="0f316-198">You can find out which columns were used as regressors by querying the model content.</span></span>  
  
 <span data-ttu-id="0f316-199">[Disponible uniquement dans certaines éditions de [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)] ]</span><span class="sxs-lookup"><span data-stu-id="0f316-199">[Available only in some editions of [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)] ]</span></span>  
  
 <span data-ttu-id="0f316-200">*MAXIMUM_INPUT_ATTRIBUTES*</span><span class="sxs-lookup"><span data-stu-id="0f316-200">*MAXIMUM_INPUT_ATTRIBUTES*</span></span>  
 <span data-ttu-id="0f316-201">Spécifie le nombre d'attributs d'entrée que l'algorithme peut traiter avant d'appeler la sélection des fonctionnalités.</span><span class="sxs-lookup"><span data-stu-id="0f316-201">Defines the number of input attributes that the algorithm can handle before it invokes feature selection.</span></span>  
  
 <span data-ttu-id="0f316-202">La valeur par défaut est 255.</span><span class="sxs-lookup"><span data-stu-id="0f316-202">The default is 255.</span></span>  
  
 <span data-ttu-id="0f316-203">Attribuez à ce paramètre la valeur 0 pour désactiver la sélection des fonctionnalités.</span><span class="sxs-lookup"><span data-stu-id="0f316-203">Set this value to 0 to turn off feature selection.</span></span>  
  
 <span data-ttu-id="0f316-204">[Disponible uniquement dans certaines éditions de [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)]]</span><span class="sxs-lookup"><span data-stu-id="0f316-204">[Available only in some editions of [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)]]</span></span>  
  
 <span data-ttu-id="0f316-205">*MAXIMUM_OUTPUT_ATTRIBUTES*</span><span class="sxs-lookup"><span data-stu-id="0f316-205">*MAXIMUM_OUTPUT_ATTRIBUTES*</span></span>  
 <span data-ttu-id="0f316-206">Spécifie le nombre d'attributs de sortie que l'algorithme peut traiter avant d'appeler la sélection des fonctionnalités.</span><span class="sxs-lookup"><span data-stu-id="0f316-206">Defines the number of output attributes that the algorithm can handle before it invokes feature selection.</span></span>  
  
 <span data-ttu-id="0f316-207">La valeur par défaut est 255.</span><span class="sxs-lookup"><span data-stu-id="0f316-207">The default is 255.</span></span>  
  
 <span data-ttu-id="0f316-208">Attribuez à ce paramètre la valeur 0 pour désactiver la sélection des fonctionnalités.</span><span class="sxs-lookup"><span data-stu-id="0f316-208">Set this value to 0 to turn off feature selection.</span></span>  
  
 <span data-ttu-id="0f316-209">[Disponible uniquement dans certaines éditions de [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)]]</span><span class="sxs-lookup"><span data-stu-id="0f316-209">[Available only in some editions of [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)]]</span></span>  
  
 <span data-ttu-id="0f316-210">*MINIMUM_SUPPORT*</span><span class="sxs-lookup"><span data-stu-id="0f316-210">*MINIMUM_SUPPORT*</span></span>  
 <span data-ttu-id="0f316-211">Spécifie le nombre minimal de cas de nœud terminal requis pour générer un fractionnement dans l'arbre de décision.</span><span class="sxs-lookup"><span data-stu-id="0f316-211">Determines the minimum number of leaf cases that is required to generate a split in the decision tree.</span></span>  
  
 <span data-ttu-id="0f316-212">La valeur par défaut est de 10.</span><span class="sxs-lookup"><span data-stu-id="0f316-212">The default is 10.</span></span>  
  
 <span data-ttu-id="0f316-213">Vous devrez peut-être augmenter cette valeur si le dataset est très grand, pour éviter le surapprentissage.</span><span class="sxs-lookup"><span data-stu-id="0f316-213">You may need to increase this value if the dataset is very large, to avoid overtraining.</span></span>  
  
 <span data-ttu-id="0f316-214">*SCORE_METHOD*</span><span class="sxs-lookup"><span data-stu-id="0f316-214">*SCORE_METHOD*</span></span>  
 <span data-ttu-id="0f316-215">Spécifie la méthode utilisée pour calculer le résultat de la division.</span><span class="sxs-lookup"><span data-stu-id="0f316-215">Determines the method that is used to calculate the split score.</span></span> <span data-ttu-id="0f316-216">Les options suivantes sont disponibles :</span><span class="sxs-lookup"><span data-stu-id="0f316-216">The following options are available:</span></span>  
  
|<span data-ttu-id="0f316-217">id</span><span class="sxs-lookup"><span data-stu-id="0f316-217">ID</span></span>|<span data-ttu-id="0f316-218">Nom</span><span class="sxs-lookup"><span data-stu-id="0f316-218">Name</span></span>|  
|--------|----------|  
|<span data-ttu-id="0f316-219">1</span><span class="sxs-lookup"><span data-stu-id="0f316-219">1</span></span>|<span data-ttu-id="0f316-220">Entropie</span><span class="sxs-lookup"><span data-stu-id="0f316-220">Entropy</span></span>|  
|<span data-ttu-id="0f316-221">3</span><span class="sxs-lookup"><span data-stu-id="0f316-221">3</span></span>|<span data-ttu-id="0f316-222">Bayésien avec a priori K2</span><span class="sxs-lookup"><span data-stu-id="0f316-222">Bayesian with K2 Prior</span></span>|  
|<span data-ttu-id="0f316-223">4</span><span class="sxs-lookup"><span data-stu-id="0f316-223">4</span></span>|<span data-ttu-id="0f316-224">Équivalent bayésien de Dirichlet (BDE) avec à priori uniforme</span><span class="sxs-lookup"><span data-stu-id="0f316-224">Bayesian Dirichlet Equivalent (BDE) with uniform prior</span></span><br /><br /> <span data-ttu-id="0f316-225">(par défaut)</span><span class="sxs-lookup"><span data-stu-id="0f316-225">(default)</span></span>|  
  
 <span data-ttu-id="0f316-226">La valeur par défaut est 4 ou BDE.</span><span class="sxs-lookup"><span data-stu-id="0f316-226">The default is 4, or BDE.</span></span>  
  
 <span data-ttu-id="0f316-227">Pour obtenir une explication de ces méthodes, consultez [Feature Selection](../../sql-server/install/feature-selection.md).</span><span class="sxs-lookup"><span data-stu-id="0f316-227">For an explanation of these scoring methods, see [Feature Selection](../../sql-server/install/feature-selection.md).</span></span>  
  
 <span data-ttu-id="0f316-228">*SPLIT_METHOD*</span><span class="sxs-lookup"><span data-stu-id="0f316-228">*SPLIT_METHOD*</span></span>  
 <span data-ttu-id="0f316-229">Spécifie la méthode utilisée pour fractionner le nœud.</span><span class="sxs-lookup"><span data-stu-id="0f316-229">Determines the method that is used to split the node.</span></span> <span data-ttu-id="0f316-230">Les options suivantes sont disponibles :</span><span class="sxs-lookup"><span data-stu-id="0f316-230">The following options are available:</span></span>  
  
|<span data-ttu-id="0f316-231">id</span><span class="sxs-lookup"><span data-stu-id="0f316-231">ID</span></span>|<span data-ttu-id="0f316-232">Nom</span><span class="sxs-lookup"><span data-stu-id="0f316-232">Name</span></span>|  
|--------|----------|  
|<span data-ttu-id="0f316-233">1</span><span class="sxs-lookup"><span data-stu-id="0f316-233">1</span></span>|<span data-ttu-id="0f316-234">**Binary:** Indique qu'indépendamment du nombre réel de valeurs pour l'attribut, l'arborescence doit être fractionnée en deux branches.</span><span class="sxs-lookup"><span data-stu-id="0f316-234">**Binary:** Indicates that regardless of the actual number of values for the attribute, the tree should be split into two branches.</span></span>|  
|<span data-ttu-id="0f316-235">2</span><span class="sxs-lookup"><span data-stu-id="0f316-235">2</span></span>|<span data-ttu-id="0f316-236">**Complete:** Indique que l'arborescence peut créer autant de divisions qu'il y a de valeurs d'attribut.</span><span class="sxs-lookup"><span data-stu-id="0f316-236">**Complete:** Indicates that the tree can create as many splits as there are attribute values.</span></span>|  
|<span data-ttu-id="0f316-237">3</span><span class="sxs-lookup"><span data-stu-id="0f316-237">3</span></span>|<span data-ttu-id="0f316-238">**Both:** Spécifie qu'Analysis Services peut déterminer si un fractionnement binaire ou complet doit être utilisé pour produire les meilleurs résultats.</span><span class="sxs-lookup"><span data-stu-id="0f316-238">**Both:** Specifies that Analysis Services can determine whether a binary or complete split should be used to produce the best results.</span></span>|  
  
 <span data-ttu-id="0f316-239">La valeur par défaut est 3.</span><span class="sxs-lookup"><span data-stu-id="0f316-239">The default is 3.</span></span>  
  
### <a name="modeling-flags"></a><span data-ttu-id="0f316-240">Indicateurs de modélisation</span><span class="sxs-lookup"><span data-stu-id="0f316-240">Modeling Flags</span></span>  
 <span data-ttu-id="0f316-241">L'algorithme MDT ( [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees) prend en charge les indicateurs de modélisation suivants.</span><span class="sxs-lookup"><span data-stu-id="0f316-241">The [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees algorithm supports the following modeling flags.</span></span> <span data-ttu-id="0f316-242">Lorsque vous créez la structure d'exploration de données ou le modèle d'exploration de données, vous définissez des indicateurs de modélisation pour spécifier la façon dont les valeurs de chaque colonne sont gérées pendant l'analyse.</span><span class="sxs-lookup"><span data-stu-id="0f316-242">When you create the mining structure or mining model, you define modeling flags to specify how values in each column are handled during analysis.</span></span> <span data-ttu-id="0f316-243">Pour plus d’informations, consultez [Indicateurs de modélisation &#40;Exploration de données&#41;](modeling-flags-data-mining.md).</span><span class="sxs-lookup"><span data-stu-id="0f316-243">For more information, see [Modeling Flags &#40;Data Mining&#41;](modeling-flags-data-mining.md).</span></span>  
  
|<span data-ttu-id="0f316-244">Indicateur de modélisation</span><span class="sxs-lookup"><span data-stu-id="0f316-244">Modeling Flag</span></span>|<span data-ttu-id="0f316-245">Description</span><span class="sxs-lookup"><span data-stu-id="0f316-245">Description</span></span>|  
|-------------------|-----------------|  
|<span data-ttu-id="0f316-246">MODEL_EXISTENCE_ONLY</span><span class="sxs-lookup"><span data-stu-id="0f316-246">MODEL_EXISTENCE_ONLY</span></span>|<span data-ttu-id="0f316-247">Signifie que la colonne sera considérée comme ayant deux états possibles : `Missing` et `Existing`.</span><span class="sxs-lookup"><span data-stu-id="0f316-247">Means that the column will be treated as having two possible states: `Missing` and `Existing`.</span></span> <span data-ttu-id="0f316-248">Une valeur NULL est une valeur manquante.</span><span class="sxs-lookup"><span data-stu-id="0f316-248">A null is a missing value.</span></span><br /><br /> <span data-ttu-id="0f316-249">S'applique aux colonnes de modèle d'exploration de données.</span><span class="sxs-lookup"><span data-stu-id="0f316-249">Applies to mining model columns.</span></span>|  
|<span data-ttu-id="0f316-250">NOT NULL</span><span class="sxs-lookup"><span data-stu-id="0f316-250">NOT NULL</span></span>|<span data-ttu-id="0f316-251">Indique que la colonne ne peut pas contenir de valeur Null.</span><span class="sxs-lookup"><span data-stu-id="0f316-251">Indicates that the column cannot contain a null.</span></span> <span data-ttu-id="0f316-252">Une erreur est générée si Analysis Services rencontre une valeur NULL au cours de l'apprentissage du modèle.</span><span class="sxs-lookup"><span data-stu-id="0f316-252">An error will result if Analysis Services encounters a null during model training.</span></span><br /><br /> <span data-ttu-id="0f316-253">S'applique aux colonnes de structure d'exploration de données.</span><span class="sxs-lookup"><span data-stu-id="0f316-253">Applies to mining structure columns.</span></span>|  
  
### <a name="regressors-in-decision-tree-models"></a><span data-ttu-id="0f316-254">Régresseurs dans les modèles d'arbre de décision</span><span class="sxs-lookup"><span data-stu-id="0f316-254">Regressors in Decision Tree Models</span></span>  
 <span data-ttu-id="0f316-255">Même si vous n'utilisez pas l'algorithme MLR ( [!INCLUDE[msCoName](../../includes/msconame-md.md)] Linear Regression), tout modèle d'arbre de décision avec des entrées et des sorties numériques continues peut potentiellement contenir des nœuds qui représentent une régression sur un attribut continu.</span><span class="sxs-lookup"><span data-stu-id="0f316-255">Even if you do not use the [!INCLUDE[msCoName](../../includes/msconame-md.md)] Linear Regression algorithm, any decision tree model that has continuous numeric inputs and outputs can potentially include nodes that represent a regression on a continuous attribute.</span></span>  
  
 <span data-ttu-id="0f316-256">Il est inutile de spécifier qu'une colonne de données numériques continues représente un régresseur.</span><span class="sxs-lookup"><span data-stu-id="0f316-256">You do not need to specify that a column of continuous numeric data represents a regressor.</span></span> <span data-ttu-id="0f316-257">L'algorithme MDT ( [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees) utilise automatiquement la colonne en tant que régresseur potentiel et partitionne le dataset en régions avec des séquences explicites même si vous ne définissez pas l'indicateur REGRESSOR sur la colonne.</span><span class="sxs-lookup"><span data-stu-id="0f316-257">The [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees algorithm will automatically use the column as a potential regressor and partition the dataset into regions with meaningful patterns even if you do not set the REGRESSOR flag on the column.</span></span>  
  
 <span data-ttu-id="0f316-258">Toutefois, vous pouvez utiliser le paramètre FORCED_REGRESSOR pour faire en sorte que l'algorithme utilise un régresseur particulier.</span><span class="sxs-lookup"><span data-stu-id="0f316-258">However, you can use the FORCE_REGRESSOR parameter to guarantee that the algorithm will use a particular regressor.</span></span> <span data-ttu-id="0f316-259">Ce paramètre peut être utilisé uniquement avec les [!INCLUDE[msCoName](../../includes/msconame-md.md)] algorithmes MDT et [!INCLUDE[msCoName](../../includes/msconame-md.md)] MLR.</span><span class="sxs-lookup"><span data-stu-id="0f316-259">This parameter can be used only with the [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees and [!INCLUDE[msCoName](../../includes/msconame-md.md)] Linear Regression algorithms.</span></span> <span data-ttu-id="0f316-260">Lorsque vous définissez l’indicateur de modélisation, l’algorithme essaie de rechercher des équations de régression de la forme a \* C1 + b \* C2 +... pour faire tenir les séquences dans les nœuds de l’arborescence.</span><span class="sxs-lookup"><span data-stu-id="0f316-260">When you set the modeling flag, the algorithm will try to find regression equations of the form a\*C1 + b\*C2 + ... to fit the patterns in the nodes of the tree.</span></span> <span data-ttu-id="0f316-261">La somme des résiduels est calculée et, si l'écart est trop grand, l'arbre est fractionné.</span><span class="sxs-lookup"><span data-stu-id="0f316-261">The sum of the residuals is calculated, and if the deviation is too great, a split is forced in the tree.</span></span>  
  
 <span data-ttu-id="0f316-262">Par exemple, si vous prédisez le comportement d'achat de vos clients en utilisant **Income** comme attribut et que vous définissez l'indicateur de modélisation REGRESSOR sur la colonne, l'algorithme essaie tout d'abord de faire tenir les valeurs **Income** en utilisant une formule de régression standard.</span><span class="sxs-lookup"><span data-stu-id="0f316-262">For example, if you are predicting customer purchasing behavior using **Income** as an attribute, and set the REGRESSOR modeling flag on the column, the algorithm will first try to fit the **Income** values by using a standard regression formula.</span></span> <span data-ttu-id="0f316-263">Si l'écart est trop grand, la formule de régression est abandonnée et l'arbre est fractionné sur un autre attribut.</span><span class="sxs-lookup"><span data-stu-id="0f316-263">If the deviation is too great, the regression formula is abandoned and the tree will be split on another attribute.</span></span> <span data-ttu-id="0f316-264">L'algorithme MDT essaie ensuite de faire tenir un régresseur pour le revenu dans chacune des branches après le fractionnement.</span><span class="sxs-lookup"><span data-stu-id="0f316-264">The decision tree algorithm will then try to fit a regressor for income in each of the branches after the split.</span></span>  
  
## <a name="requirements"></a><span data-ttu-id="0f316-265">Configuration requise</span><span class="sxs-lookup"><span data-stu-id="0f316-265">Requirements</span></span>  
 <span data-ttu-id="0f316-266">Un modèle d'arbre de décision doit contenir une colonne clé, des colonnes d'entrée et au moins une colonne prédictible.</span><span class="sxs-lookup"><span data-stu-id="0f316-266">A decision tree model must contain a key column, input columns, and at least one predictable column.</span></span>  
  
### <a name="input-and-predictable-columns"></a><span data-ttu-id="0f316-267">Colonnes d'entrée et prédictibles</span><span class="sxs-lookup"><span data-stu-id="0f316-267">Input and Predictable Columns</span></span>  
 <span data-ttu-id="0f316-268">L'algorithme MDT ( [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees) prend en charge les colonnes d'entrée et les colonnes prédictibles répertoriées dans le tableau suivant.</span><span class="sxs-lookup"><span data-stu-id="0f316-268">The [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees algorithm supports the specific input columns and predictable columns that are listed in the following table.</span></span> <span data-ttu-id="0f316-269">Pour plus d’informations sur la signification des types de contenu en cas d’utilisation dans un modèle d’exploration de données, consultez [Types de contenu &#40;Exploration de données&#41;](content-types-data-mining.md).</span><span class="sxs-lookup"><span data-stu-id="0f316-269">For more information about what the content types mean when used in a mining model, see [Content Types &#40;Data Mining&#41;](content-types-data-mining.md).</span></span>  
  
|<span data-ttu-id="0f316-270">Colonne</span><span class="sxs-lookup"><span data-stu-id="0f316-270">Column</span></span>|<span data-ttu-id="0f316-271">Types de contenu</span><span class="sxs-lookup"><span data-stu-id="0f316-271">Content types</span></span>|  
|------------|-------------------|  
|<span data-ttu-id="0f316-272">Attribut d'entrée</span><span class="sxs-lookup"><span data-stu-id="0f316-272">Input attribute</span></span>|<span data-ttu-id="0f316-273">Continu, cyclique, discret, discrétisé, clé, trié, table</span><span class="sxs-lookup"><span data-stu-id="0f316-273">Continuous, Cyclical, Discrete, Discretized, Key, Ordered, Table</span></span>|  
|<span data-ttu-id="0f316-274">Attribut prédictible</span><span class="sxs-lookup"><span data-stu-id="0f316-274">Predictable attribute</span></span>|<span data-ttu-id="0f316-275">Continu, cyclique, discret, discrétisé, trié, table</span><span class="sxs-lookup"><span data-stu-id="0f316-275">Continuous, Cyclical, Discrete, Discretized, Ordered, Table</span></span>|  
  
> [!NOTE]  
>  <span data-ttu-id="0f316-276">Les types de contenu Cyclique et Trié sont pris en charge, mais l'algorithme les traite comme des valeurs discrètes et n'effectue pas de traitement spécial.</span><span class="sxs-lookup"><span data-stu-id="0f316-276">Cyclical and Ordered content types are supported, but the algorithm treats them as discrete values and does not perform special processing.</span></span>  
  
## <a name="see-also"></a><span data-ttu-id="0f316-277">Voir aussi</span><span class="sxs-lookup"><span data-stu-id="0f316-277">See Also</span></span>  
 <span data-ttu-id="0f316-278">[Algorithme MDT (Microsoft Decision Trees)](microsoft-decision-trees-algorithm.md) </span><span class="sxs-lookup"><span data-stu-id="0f316-278">[Microsoft Decision Trees Algorithm](microsoft-decision-trees-algorithm.md) </span></span>  
 <span data-ttu-id="0f316-279">[Exemples de requêtes de modèle d’arbre de décision](decision-trees-model-query-examples.md) </span><span class="sxs-lookup"><span data-stu-id="0f316-279">[Decision Trees Model Query Examples](decision-trees-model-query-examples.md) </span></span>  
 [<span data-ttu-id="0f316-280">Contenu du modèle d’exploration de données pour les modèles d’arbre de décision &#40;Analysis Services - Exploration de données&#41;</span><span class="sxs-lookup"><span data-stu-id="0f316-280">Mining Model Content for Decision Tree Models &#40;Analysis Services - Data Mining&#41;</span></span>](mining-model-content-for-decision-tree-models-analysis-services-data-mining.md)  
  
  
